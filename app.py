import os
import sqlite3
import matplotlib
matplotlib.use('Agg') 
import matplotlib.pyplot as plt
import pandas as pd
import streamlit as st

from typing import Annotated, List
from typing_extensions import TypedDict
from langchain_openai import ChatOpenAI
from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage
from langchain_core.tools import tool
from langchain_experimental.utilities import PythonREPL
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.graph.message import add_messages
from langgraph.checkpoint.sqlite import SqliteSaver

from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings

import base64
from e2b_code_interpreter import Sandbox

def save_uploaded_file(uploaded_file):
    file_path = uploaded_file.name
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    return file_path

def get_dataframe_info(df: pd.DataFrame) -> str:
    buf = []
    buf.append(f"1. åˆ—ååˆ—è¡¨: {list(df.columns)}")
    buf.append(f"2. æ•°æ®ç±»å‹:\n{df.dtypes.to_string()}")
    buf.append(f"3. å‰3è¡Œæ•°æ®é¢„è§ˆ:\n{df.head(3).to_string()}")
    return "\n".join(buf)
# --- æ–°å¢å‡½æ•°ï¼šå¤„ç† PDF å¹¶æ„å»ºå‘é‡åº“ ---
@st.cache_resource
def create_vector_db(file_path,api_key,base_url):
    
    loader = PyPDFLoader(file_path)
    docs = loader.load()
    
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = text_splitter.split_documents(docs)
    
    embeddings = OpenAIEmbeddings(
        model="text-embedding-3-small",
        openai_api_key=api_key, 
        openai_api_base=base_url 
    )
    vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)
    return vectorstore

st.set_page_config(page_title="DeepSeek æ•°æ®åˆ†æå¸ˆ", layout="wide")
st.title("DeepSeek æ•°æ®åˆ†æå¸ˆ")

with st.sidebar:
    st.header("âš™ï¸ æ§åˆ¶å°")
    api_key = st.text_input("DeepSeek API Key (ç”¨äºå¯¹è¯)", type="password", value="")
    e2b_api_key = st.text_input(
        "E2B API Key (ç”¨äºæ²™ç›’å®‰å…¨æ‰§è¡Œ)", 
        type="password", 
        help="å» e2b.dev ç”³è¯·ï¼Œç”¨äºåœ¨äº‘ç«¯éš”ç¦»ç¯å¢ƒä¸­è¿è¡Œä»£ç "
    )
    embedding_api_key = st.text_input(
        "Embedding API Key (ç”¨äºçŸ¥è¯†åº“)", 
        type="password", 
        value="", # ä½ çš„ Embedding ä¸“ç”¨ Key
        help="ç”¨äº OpenAIEmbeddings çš„ Keyï¼Œé€šå¸¸æ˜¯ OpenAI å®˜æ–¹æˆ–ä¸­è½¬æœåŠ¡çš„ Key"
    )
    
    embedding_base_url = st.text_input(
        "Embedding Base URL", 
        value="https://poloai.top/v1", 
        help="å¦‚æœæ˜¯ä¸­è½¬æœåŠ¡ï¼Œè¯·å¡«å†™ Base URL"
    )

    st.divider()
    st.subheader("ğŸ’¾ è®°å¿†ç®¡ç†")
    thread_id = st.text_input("ä¼šè¯ ID (Thread ID)", value="session_1", help="è¾“å…¥ä¸åŒçš„ ID å¯ä»¥åˆ‡æ¢ä¸åŒçš„å¯¹è¯å†å²")
    
    st.subheader("ğŸ“‚ æ•°æ®åŠ è½½")
    uploaded_file = st.file_uploader("ä¸Šä¼ æ•°æ®è¡¨(CSV/Excel)", type=["csv", "xlsx"])
    uploaded_pdf = st.file_uploader("ä¸Šä¼ çŸ¥è¯†åº“ (PDF)", type=["pdf"])
    
    current_file_path = None
    df_info_str = "" 

    if uploaded_file:
        current_file_path = save_uploaded_file(uploaded_file)
        st.success(f"å·²åŠ è½½: {uploaded_file.name}")
        try:
            if current_file_path.endswith(".csv"):
                df = pd.read_csv(current_file_path)
            else:
                df = pd.read_excel(current_file_path)
            df_info_str = get_dataframe_info(df)
            with st.expander("ğŸ‘€ æ•°æ®é€è§†"):
                st.text(df_info_str)
        except Exception as e:
            st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
    if uploaded_pdf:
        pdf_path = save_uploaded_file(uploaded_pdf)
        st.success(f"çŸ¥è¯†åº“å·²åŠ è½½: {uploaded_pdf.name}")
        
        if not embedding_api_key:
            st.error("âŒ è¯·å…ˆåœ¨ä¸Šæ–¹å¡«å…¥ Embedding API Keyï¼")
            st.stop()

        try:
            with st.spinner("æ­£åœ¨æ„å»ºçŸ¥è¯†åº“ç´¢å¼• (RAG)..."):
                vector_db = create_vector_db(pdf_path, embedding_api_key, embedding_base_url)
                
                st.session_state["vector_db"] = vector_db
                st.success("âœ… çŸ¥è¯†åº“ç´¢å¼•æ„å»ºå®Œæˆï¼")
        except Exception as e:
            st.error(f"çŸ¥è¯†åº“æ„å»ºå¤±è´¥: {e}")
    # å°†æ•°æ®å­˜å…¥ Session ä¾› Tool è¯»å–
    if current_file_path:
        st.session_state["current_file_path"] = current_file_path
    
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå½“å‰ä¼šè¯å†å²"):
        # è¿™é‡Œåªæ˜¯ç®€å•æ¸…ç©º UIï¼Œæ•°æ®åº“é‡Œçš„è¿˜åœ¨ï¼Œé™¤éæ‰‹åŠ¨åˆ  DB è®°å½•
        # å®é™…é¡¹ç›®ä¸­å¯ä»¥è°ƒç”¨ checkpointer çš„åˆ é™¤æ–¹æ³•ï¼Œè¿™é‡Œç®€å•å¤„ç†ï¼šæ¢ä¸ª ID å°±è¡Œ
        st.session_state.messages = []
        st.rerun()

# 3. Agent å®šä¹‰ (å¸¦ Checkpointer)
@st.cache_resource
def get_agent(_api_key):
    
    # --- 1. å®šä¹‰å¢å¼ºç‰ˆå·¥å…· (è‡ªåŠ¨æ³¨å…¥ç¯å¢ƒ) ---
    @tool
    def python_interpreter(code: str):
        """
        [E2B äº‘ç«¯æ²™ç›’ç‰ˆ] Python ä»£ç æ‰§è¡Œå™¨ã€‚
        ä»£ç å°†åœ¨å®‰å…¨çš„äº‘ç«¯éš”ç¦»ç¯å¢ƒä¸­è¿è¡Œï¼Œæ”¯æŒ pandas, matplotlib ç­‰åº“ã€‚
        """
        
        # 1. æ£€æŸ¥ Key æ˜¯å¦å­˜åœ¨
        if not e2b_api_key:
            return "âŒ é”™è¯¯: æœªé…ç½® E2B API Keyï¼Œæ— æ³•å¯åŠ¨äº‘ç«¯æ²™ç›’ã€‚"
            
        try:
            # 2. å¯åŠ¨äº‘ç«¯æ²™ç›’ (ä½¿ç”¨ Context Manager è‡ªåŠ¨å…³é—­)
            # è¿™ä¸€æ­¥éœ€è¦å‡ ç§’é’Ÿå¯åŠ¨å®¹å™¨
            print("â³ æ­£åœ¨å¯åŠ¨ E2B æ²™ç›’...")
            with Sandbox(api_key=e2b_api_key) as sbx:
                
                # --- A. æ–‡ä»¶åŒæ­¥ (Local -> Cloud) ---
                # æˆ‘ä»¬éœ€è¦æŠŠ Streamlit é‡Œçš„æ•°æ®æ–‡ä»¶ä¸Šä¼ åˆ°æ²™ç›’çš„ /home/user ç›®å½•ä¸‹
                if "current_file_path" in st.session_state:
                    local_path = st.session_state["current_file_path"]
                    if os.path.exists(local_path):
                        with open(local_path, "rb") as f:
                            # ä¸Šä¼ æ–‡ä»¶ï¼Œå¹¶ä¿æŒæ–‡ä»¶åä¸€è‡´
                            sbx.files.write(os.path.basename(local_path), f)
                            print(f"âœ… æ–‡ä»¶å·²ä¸Šä¼ è‡³æ²™ç›’: {local_path}")
                
                # --- B. ä»£ç é¢„å¤„ç† (ç¯å¢ƒæ³¨å…¥) ---
                clean_code = code.strip().replace("```python", "").replace("```", "")
                
                header = []
                header.append("import pandas as pd")
                header.append("import matplotlib.pyplot as plt")
                
                # é’ˆå¯¹æ²™ç›’ç¯å¢ƒï¼Œæˆ‘ä»¬éœ€è¦è®¾ç½®éäº¤äº’åç«¯ï¼Œä¸”ä¸ç”¨è®¾ç½®ä¸­æ–‡å­—ä½“
                # (E2B ç¯å¢ƒé€šå¸¸æ˜¯ Linuxï¼Œè£…ä¸­æ–‡å­—ä½“æ¯”è¾ƒéº»çƒ¦ï¼Œå»ºè®®å…ˆç”¨è‹±æ–‡ï¼Œæˆ–è€…ä¸Šä¼ å­—ä½“æ–‡ä»¶)
                # ä¸ºäº†æ¼”ç¤ºç®€å•ï¼Œæˆ‘ä»¬å…ˆä¸å¼ºåˆ¶è®¾ç½®å­—ä½“ï¼Œæˆ–è€…ä½¿ç”¨é»˜è®¤å…¼å®¹è®¾ç½®
                header.append("plt.switch_backend('Agg')") 
                
                # è‡ªåŠ¨åŠ è½½æ•°æ®é€»è¾‘
                if "current_file_path" in st.session_state:
                    fname = os.path.basename(st.session_state["current_file_path"])
                    if fname.endswith(".csv"):
                        header.append(f"df = pd.read_csv('{fname}')")
                    elif fname.endswith((".xls", ".xlsx")):
                        header.append(f"df = pd.read_excel('{fname}')")

                full_code = "\n".join(header) + "\n" + clean_code
                
                # --- C. æ‰§è¡Œä»£ç  ---
                print(f"--- Cloud Executing ---\n{full_code}\n-----------------------")
                execution = sbx.run_code(full_code)
                
                # --- D. å¤„ç†ç»“æœ (Logs & Errors) ---
                output_log = ""
                if execution.error:
                    return f"âŒ ä»£ç æ‰§è¡ŒæŠ¥é”™:\n{execution.error.name}: {execution.error.value}\n{execution.error.traceback}"
                
                if execution.logs.stdout:
                    output_log += f"ğŸ“„ è¾“å‡º:\n{str(execution.logs.stdout)}\n"
                
                # --- E. å¤„ç†å›¾ç‰‡ (Base64 -> Local PNG) ---
                # E2B ä¼šæŠŠç”Ÿæˆçš„å›¾æ”¾åœ¨ execution.results é‡Œ
                for result in execution.results:
                    # æ£€æŸ¥æ˜¯å¦æœ‰ png æ ¼å¼çš„è¾“å‡º
                    if hasattr(result, 'png') and result.png:
                        # è§£ç  Base64
                        img_data = base64.b64decode(result.png)
                        # ä¿å­˜åˆ° Streamlit æœ¬åœ°ç›®å½•ï¼Œä»¥ä¾¿å‰ç«¯æ˜¾ç¤º
                        with open("result.png", "wb") as f:
                            f.write(img_data)
                        output_log += "\nğŸ–¼ï¸ å›¾è¡¨å·²ç”Ÿæˆå¹¶ä¿å­˜ä¸º result.png"
                
                if not output_log:
                    output_log = "ä»£ç æ‰§è¡ŒæˆåŠŸï¼Œæ— æ–‡æœ¬è¾“å‡ºã€‚"
                    
                return output_log

        except Exception as e:
            return f"æ²™ç›’è¿æ¥æˆ–æ‰§è¡Œå¤±è´¥: {e}"

    @tool
    def lookup_policy(query: str):
        """
        åªæœ‰å½“ç”¨æˆ·è¯¢é—®å…·ä½“çš„ä¸šåŠ¡æ–‡æ¡£ã€æ”¿ç­–ã€æŠ¥å‘Šå†…å®¹æ—¶æ‰ä½¿ç”¨æ­¤å·¥å…·ã€‚
        è¾“å…¥åº”è¯¥æ˜¯å…·ä½“çš„æŸ¥è¯¢é—®é¢˜ã€‚
        """
        if "vector_db" not in st.session_state:
            return "ç”¨æˆ·è¿˜æœªä¸Šä¼ æ–‡æ¡£ï¼Œæ— æ³•æ£€ç´¢ã€‚"
        
        # è·å–æ£€ç´¢å™¨
        db = st.session_state["vector_db"]
        retriever = db.as_retriever(search_kwargs={"k": 3}) # æ‰¾æœ€ç›¸å…³çš„3æ®µè¯
        results = retriever.invoke(query)
        
        # æŠŠæ‰¾å‡ºæ¥çš„å†…å®¹æ‹¼æ¥æˆå­—ç¬¦ä¸²
        return "\n\n".join([doc.page_content for doc in results])
    tools = [python_interpreter, lookup_policy]

    llm = ChatOpenAI(
        api_key=_api_key,
        base_url="https://api.deepseek.com",
        model="deepseek-chat",
        temperature=0
    )
    llm_with_tools = llm.bind_tools(tools)

    class AgentState(TypedDict):
        messages: Annotated[List[BaseMessage], add_messages]

    def agent_node(state: AgentState):
        messages = state["messages"]
        
        # åŠ¨æ€è·å– Prompt æ•°æ®
        file_path = st.session_state.get("current_file_path", "data.csv")
        data_context = df_info_str if df_info_str else "æš‚æ— æ•°æ®"

        sys_msg = SystemMessage(content=f"""ä½ æ˜¯ä¸€ä¸ªé«˜çº§æ•°æ®åˆ†ææ™ºèƒ½ä½“ï¼Œæ‹¥æœ‰ä¸¤å¤§æ ¸å¿ƒèƒ½åŠ›ï¼š
        1. ğŸ **Python ä»£ç æ‰§è¡Œ**ï¼šç”¨äºå¤„ç†æ•°æ®ã€è®¡ç®—ç»Ÿè®¡é‡ã€ç»˜åˆ¶å›¾è¡¨ã€‚
        2. ğŸ“š **çŸ¥è¯†åº“æ£€ç´¢**ï¼šç”¨äºæŸ¥è¯¢å…·ä½“çš„ä¸šåŠ¡æ–‡æ¡£ã€æ”¿ç­–ã€æŠ¥å‘ŠåŸæ–‡ã€‚

        ã€å½“å‰æ•°æ®ç¯å¢ƒã€‘
        1. æ•°æ®æ–‡ä»¶è·¯å¾„: '{file_path}'
        2. æ•°æ®æ‘˜è¦: {data_context}

        ã€è°ƒåº¦å†³ç­–å‡†åˆ™ã€‘
        - ğŸ“Š **é‡åˆ°æ•°æ®è®¡ç®—ã€ç”»å›¾éœ€æ±‚**ï¼šè¯·ç¼–å†™ Python ä»£ç ï¼Œä½¿ç”¨ `df` å˜é‡ã€‚
        - â“ **é‡åˆ°ä¸šåŠ¡å«ä¹‰ã€æ”¿ç­–è§£é‡Šã€èƒŒæ™¯çŸ¥è¯†æŸ¥è¯¢**ï¼šè¯·åŠ¡å¿…è°ƒç”¨ `lookup_policy` å·¥å…·æ£€ç´¢çŸ¥è¯†åº“ï¼Œ**ä¸¥ç¦å‡­ç©ºç¼–é€ **ã€‚
        - ğŸ¤ **æ··åˆéœ€æ±‚**ï¼šå¦‚æœç”¨æˆ·é—®â€œæ ¹æ®æœ€æ–°çš„é”€å”®æ”¿ç­–ï¼ˆPDFï¼‰ï¼Œåˆ†æè¿™ä»½æ•°æ®ï¼ˆCSVï¼‰â€ï¼Œä½ éœ€è¦å…ˆæŸ¥çŸ¥è¯†åº“ï¼Œç†è§£æ”¿ç­–ï¼Œå†å†™ä»£ç åˆ†ææ•°æ®ã€‚
        
        ã€äº‘ç«¯æ‰§è¡Œé¡»çŸ¥ã€‘
        1. ä½ çš„ä»£ç æ˜¯åœ¨äº‘ç«¯ Linux æ²™ç›’ä¸­è¿è¡Œçš„ã€‚
        2. æ•°æ®æ–‡ä»¶å·²ç»è‡ªåŠ¨ä¸Šä¼ åˆ°å½“å‰ç›®å½•ã€‚
        3. âš ï¸ ç»˜å›¾æ—¶ï¼Œä¸ºäº†é¿å… Linux å­—ä½“ç¼ºå¤±å¯¼è‡´ä¹±ç ï¼Œ**å›¾è¡¨çš„æ ‡é¢˜å’Œè½´æ ‡ç­¾è¯·å°½é‡ä½¿ç”¨è‹±æ–‡**ã€‚
           (ä¾‹å¦‚: ä½¿ç”¨ 'Sales' è€Œä¸æ˜¯ 'é”€å”®é¢')
        
        ã€æ‰§è¡Œé“å¾‹ã€‘
        1. ğŸš« ä¸¥ç¦ input() å’Œ plt.show()ã€‚
        2. âœ… ç»˜å›¾å¿…é¡»ä¿å­˜ä¸º 'result.png'ã€‚
        3. âœ… æŸ¥çŸ¥è¯†åº“æ—¶ï¼Œå¦‚æœæŸ¥ä¸åˆ°å†…å®¹ï¼Œè¯·ç›´æ¥å‘Šè¯‰ç”¨æˆ·â€œçŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯â€ã€‚
        """)
        
        # æ¶ˆæ¯é˜Ÿåˆ—å¤„ç†
        new_messages = list(messages)
        if isinstance(new_messages[0], SystemMessage):
            new_messages[0] = sys_msg
        else:
            new_messages.insert(0, sys_msg)
            
        return {"messages": [llm_with_tools.invoke(new_messages)]}

    tool_node = ToolNode(tools)
    workflow = StateGraph(AgentState)
    workflow.add_node("agent", agent_node)
    workflow.add_node("tools", tool_node)
    workflow.set_entry_point("agent")
    workflow.add_conditional_edges("agent", tools_condition)
    workflow.add_edge("tools", "agent")

    # ğŸ”¥ã€é˜¶æ®µ3æ ¸å¿ƒã€‘åˆå§‹åŒ– SQLite è®°å¿†æ•°æ®åº“
    # check_same_thread=False å…è®¸ Streamlit å¤šçº¿ç¨‹è®¿é—®
    conn = sqlite3.connect("memory.sqlite", check_same_thread=False)
    memory = SqliteSaver(conn)
    
    # ç¼–è¯‘æ—¶ä¼ å…¥ checkpointer
    return workflow.compile(checkpointer=memory)

# åˆå§‹åŒ– Agent
if api_key:
    app = get_agent(api_key)


# ä» LangGraph æ•°æ®åº“åŠ è½½å†å²æ¶ˆæ¯
# æˆ‘ä»¬ä¸å†ä¾èµ– st.session_state.messages è¿™ç§ä¸´æ—¶å˜é‡
# è€Œæ˜¯ç›´æ¥å»æ•°æ®åº“é‡ŒæŸ¥è¿™ä¸ª thread_id æœ‰æ²¡æœ‰å†å²è®°å½•
current_config = {"configurable": {"thread_id": thread_id}}

if "messages" not in st.session_state:
    st.session_state.messages = []

# å°è¯•ä» checkpointer è·å–å½“å‰çŠ¶æ€
try:
    snapshot = app.get_state(current_config)
    if snapshot.values and "messages" in snapshot.values:
        # å¦‚æœæ•°æ®åº“é‡Œæœ‰è®°å½•ï¼Œå°±æ˜¾ç¤ºæ•°æ®åº“é‡Œçš„
        # è¿‡æ»¤æ‰ SystemMessageï¼Œåªæ˜¾ç¤º User å’Œ AI
        st.session_state.messages = [
            {"role": "user" if isinstance(m, HumanMessage) else "assistant", "content": m.content}
            for m in snapshot.values["messages"]
            if not isinstance(m, SystemMessage) and not isinstance(m, BaseMessage) # ToolMessage è¿™é‡Œç®€åŒ–å¤„ç†ä¸æ˜¾ç¤º
            and m.content # è¿‡æ»¤ç©ºæ¶ˆæ¯
        ]
except Exception as e:
    # ç¬¬ä¸€æ¬¡å¯èƒ½æ˜¯ç©ºçš„ï¼Œå¿½ç•¥
    pass

# æ˜¾ç¤ºå†å²
for msg in st.session_state.messages:
    # ç®€å•è¿‡æ»¤ ToolMessage (å®ƒçš„ role å¯èƒ½æ˜¯ tool)
    if msg["role"] in ["user", "assistant"]:
        st.chat_message(msg["role"]).write(msg["content"])

# å¤„ç†è¾“å…¥
if prompt := st.chat_input("è¾“å…¥ä½ çš„åˆ†æéœ€æ±‚..."):
    if not current_file_path and "vector_db" not in st.session_state:
        st.warning("âš ï¸ ä½ æ—¢æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œä¹Ÿæ²¡æœ‰ä¸Šä¼ çŸ¥è¯†åº“ï¼Œæˆ‘å¯èƒ½æ— æ³•å›ç­”ä¸“ä¸šé—®é¢˜ã€‚")

    st.chat_message("user").write(prompt)

    st.chat_message("user").write(prompt)
    # è¿™é‡Œçš„ append åªæ˜¯ä¸ºäº† UI å³ä½¿æ˜¾ç¤ºï¼ŒçœŸæ­£çš„å­˜å‚¨åœ¨ LangGraph é‡Œ
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        status_box = st.status("ğŸ§  DeepSeek æ­£åœ¨å›å¿†å¹¶æ€è€ƒ...", expanded=True)
        
        try:
            # ç›´æ¥æŠŠæ–°æ¶ˆæ¯ä¸¢ç»™ appï¼Œå¸¦ä¸Š thread_id
            # LangGraph ä¼šè‡ªåŠ¨å»æ•°æ®åº“æ‰¾ä¹‹å‰çš„å†å²ï¼Œæ‹¼åœ¨ä¸€èµ·å‘ç»™ DeepSeek
            inputs = {"messages": [HumanMessage(content=prompt)]}
            
            response_content = ""
            
            # è®°å¾—æŠŠ recursion_limit è°ƒå¤§
            events = app.stream(inputs, config=current_config)
            
            for event in events:
                if "agent" in event:
                    msg = event["agent"]["messages"][-1]
                    status_box.write(f"ğŸ’¬ æ€è€ƒ: {msg.content}")
                    response_content = msg.content
                if "tools" in event:
                    tool_msg = event["tools"]["messages"][-1]
                    status_box.code(f"ğŸ› ï¸ æ‰§è¡Œç»“æœ: {tool_msg.content[:300]}")

            status_box.update(label="âœ… å®Œæˆ", state="complete", expanded=False)
            
            if response_content:
                st.write(response_content)
                # åˆ·æ–° UI çŠ¶æ€
                st.session_state.messages.append({"role": "assistant", "content": response_content})
            
            if os.path.exists("result.png"):
                st.image("result.png")

        except Exception as e:
            st.error(f"å‘ç”Ÿé”™è¯¯: {e}")